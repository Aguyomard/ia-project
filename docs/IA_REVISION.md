# ğŸ“š RÃ©vision - IntÃ©gration IA avec Node.js

> RÃ©capitulatif technique de l'intÃ©gration de Mistral AI dans une application Node.js/Express avec Vue.js

---

## ğŸ“‹ Table des matiÃ¨res

1. [Architecture globale](#1-architecture-globale)
2. [MistralService - Le cÅ“ur de l'IA](#2-mistralservice---le-cÅ“ur-de-lia)
3. [Robustesse - Retry avec Exponential Backoff](#3-robustesse---retry-avec-exponential-backoff)
4. [Gestion du Contexte - Sliding Window](#4-gestion-du-contexte---sliding-window)
5. [Streaming avec SSE](#5-streaming-avec-sse)
6. [Persistance avec Prisma](#6-persistance-avec-prisma)
7. [Embeddings et Recherche Vectorielle](#7-embeddings-et-recherche-vectorielle)
8. [RAG - Retrieval-Augmented Generation](#8-rag---retrieval-augmented-generation)
9. [Architecture Clean Architecture](#9-architecture-clean-architecture)
10. [Frontend Vue.js](#10-frontend-vuejs)
11. [Concepts clÃ©s Ã  retenir](#11-concepts-clÃ©s-Ã -retenir)

---

## 1. Architecture globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND (Vue.js)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ChatBot    â”‚  â”‚  Documents  â”‚  â”‚  Vue Router             â”‚  â”‚
â”‚  â”‚  View       â”‚  â”‚  View (RAG) â”‚  â”‚  /chat, /documents      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ HTTP / SSE
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND (Clean Architecture)                    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ”´ INFRASTRUCTURE                                         â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ http/ (Routes, Controllers)                         â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ persistence/ (Repositories Prisma)                  â”‚   â”‚
â”‚  â”‚  â””â”€â”€ external/ (MistralClient)                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ”µ APPLICATION                                            â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ usecases/ (StreamMessageUseCase, AddDocumentUseCase)â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ services/ (ConversationService, RAGService)         â”‚   â”‚
â”‚  â”‚  â””â”€â”€ ports/ (Interfaces IMistralClient, IRAGService)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸŸ¢ DOMAIN                                                 â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ entities/ (Conversation, Message, Document)         â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ valueObjects/ (MessageRole, Embedding, UUID)        â”‚   â”‚
â”‚  â”‚  â””â”€â”€ repositories/ (Interfaces IConversationRepository)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MISTRAL AI API      â”‚    â”‚     POSTGRESQL          â”‚
â”‚  - Chat (mistral-tiny)  â”‚    â”‚  - Prisma ORM           â”‚
â”‚  - Embeddings           â”‚    â”‚  - pgvector (RAG)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. MistralService - Le cÅ“ur de l'IA

### 2.1 Structure du service

```typescript
// src/services/mistral/MistralService.ts

export class MistralService {
  private readonly client: Mistral; // SDK Mistral
  private readonly defaultModel: string; // ex: 'mistral-tiny'
  private readonly defaultTemperature: number; // ex: 0.7
  private readonly retryOptions: RetryOptions; // Config retry

  constructor(config: MistralConfig = {}) {
    // Initialisation avec API key depuis env ou config
  }
}
```

### 2.2 MÃ©thodes principales

| MÃ©thode                             | Description           | Retour                  |
| ----------------------------------- | --------------------- | ----------------------- |
| `chat(message, options)`            | Message simple        | `Promise<string>`       |
| `chatJSON<T>(message, options)`     | RÃ©ponse JSON typÃ©e    | `Promise<T>`            |
| `complete(messages, options)`       | Conversation complÃ¨te | `Promise<string>`       |
| `streamComplete(messages, options)` | Streaming             | `AsyncIterable<string>` |
| `streamChat(message, options)`      | Streaming simple      | `AsyncIterable<string>` |

### 2.3 Options disponibles

```typescript
interface ChatOptions {
  model?: string; // ModÃ¨le Ã  utiliser
  systemPrompt?: string; // Prompt systÃ¨me
  temperature?: number; // CrÃ©ativitÃ© (0-1)
  maxTokens?: number; // Limite de tokens en sortie
  jsonMode?: boolean; // Forcer rÃ©ponse JSON
  autoTruncate?: boolean; // Sliding window auto
  reservedForResponse?: number; // Tokens rÃ©servÃ©s pour rÃ©ponse
}
```

### 2.4 Pattern Singleton

```typescript
// RÃ©cupÃ©rer l'instance unique
const mistral = getMistralService();

// Reset pour les tests
resetMistralService();
```

**Pourquoi ?** Ã‰vite de crÃ©er plusieurs clients, partage la configuration.

---

## 3. Robustesse - Retry avec Exponential Backoff

### 3.1 Le problÃ¨me

Les API d'IA sont **fragiles** :

- `429` Too Many Requests (rate limit)
- `500/502/503/504` Erreurs serveur
- `ECONNRESET` Connexion coupÃ©e

### 3.2 La solution : Exponential Backoff

```
Tentative 1 â†’ Ã‰chec (429)
    â†“ Attendre 1s
Tentative 2 â†’ Ã‰chec (503)
    â†“ Attendre 2s
Tentative 3 â†’ Ã‰chec (500)
    â†“ Attendre 4s
Tentative 4 â†’ SuccÃ¨s âœ…
```

### 3.3 ImplÃ©mentation

```typescript
// src/utils/retry.ts

export async function withRetry<T>(
  fn: () => Promise<T>,
  options: RetryOptions = {}
): Promise<T> {
  const { maxRetries = 3, baseDelay = 1000, multiplier = 2 } = options;

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      if (attempt >= maxRetries || !shouldRetry(error)) {
        throw error;
      }
      const delay = baseDelay * Math.pow(multiplier, attempt);
      await sleep(delay);
    }
  }
}
```

### 3.4 Jitter (variation alÃ©atoire)

```typescript
// Ã‰vite le "thundering herd" (tous les clients retentent en mÃªme temps)
const jitter = exponentialDelay * 0.25 * (Math.random() * 2 - 1);
const finalDelay = exponentialDelay + jitter;
```

### 3.5 Configuration

| ParamÃ¨tre    | DÃ©faut  | Description              |
| ------------ | ------- | ------------------------ |
| `maxRetries` | 3       | Nombre max de tentatives |
| `baseDelay`  | 1000ms  | DÃ©lai initial            |
| `multiplier` | 2       | Facteur d'augmentation   |
| `maxDelay`   | 30000ms | DÃ©lai max (30s)          |

### 3.6 Erreurs retryables

```typescript
const RETRYABLE_STATUS_CODES = [429, 500, 502, 503, 504];
const RETRYABLE_NETWORK_ERRORS = ['ECONNRESET', 'ETIMEDOUT', 'ECONNREFUSED'];
```

---

## 4. Gestion du Contexte - Sliding Window

### 4.1 Le problÃ¨me

Chaque modÃ¨le a une **limite de contexte** :

| ModÃ¨le               | Limite         |
| -------------------- | -------------- |
| mistral-tiny         | 32 000 tokens  |
| mistral-large-latest | 128 000 tokens |
| GPT-4o               | 128 000 tokens |

Si dÃ©passÃ© â†’ Erreur `400 Bad Request - Context Length Exceeded`

### 4.2 La solution : Sliding Window

```
AVANT (50 messages, ~35000 tokens)
[System] Tu es un assistant...
[User] Message 1
[Assistant] RÃ©ponse 1
[User] Message 2
...
[User] Message 50        â† DÃ©passe la limite !

APRÃˆS (sliding window)
[System] Tu es un assistant...  â† TOUJOURS gardÃ©
[User] Message 35               â† Messages rÃ©cents
[Assistant] RÃ©ponse 35
...
[User] Message 50               â† OK, ~28000 tokens
```

### 4.3 Estimation des tokens

```typescript
// Approximation : 1 token â‰ˆ 3.5 caractÃ¨res
export function estimateTokens(text: string): number {
  const charCount = text.length;
  const tokenEstimate = Math.ceil(charCount / 3.5);
  return tokenEstimate + 4; // +4 pour overhead
}
```

### 4.4 Algorithme

```typescript
export function applySlidingWindow(
  messages: ChatMessage[],
  config: SlidingWindowConfig
): ChatMessage[] {
  // 1. SÃ©parer le system prompt
  // 2. Parcourir du plus rÃ©cent au plus ancien
  // 3. Ajouter tant qu'on reste sous le budget
  // 4. Remettre le system prompt en premier
}
```

### 4.5 RÃ¨gles

| RÃ¨gle                  | Valeur | Raison                              |
| ---------------------- | ------ | ----------------------------------- |
| `preserveSystemPrompt` | true   | Le contexte de base est crucial     |
| `reservedForResponse`  | 1000   | Laisser de la place pour la rÃ©ponse |
| `minMessages`          | 2      | Garder un minimum de contexte       |

### 4.6 IntÃ©gration automatique

```typescript
// Dans MistralService, c'est automatique !
public async complete(messages, options) {
  const { autoTruncate = true } = options;

  if (autoTruncate) {
    messages = applySlidingWindow(messages, {
      maxTokens: getModelContextLimit(model),
      reservedForResponse: 1000,
    });
  }
  // ...
}
```

---

## 5. Streaming avec SSE

### 5.1 Pourquoi le streaming ?

| Sans streaming                          | Avec streaming                         |
| --------------------------------------- | -------------------------------------- |
| Attendre 5-10s pour la rÃ©ponse complÃ¨te | Voir les mots apparaÃ®tre en temps rÃ©el |
| UX frustrante                           | UX fluide comme ChatGPT                |

### 5.2 Server-Sent Events (SSE)

**CÃ´tÃ© serveur :**

```typescript
// conversationController.ts
export async function chat(req: Request, res: Response) {
  // Headers SSE
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');
  res.flushHeaders();

  // Stream les chunks
  for await (const chunk of mistral.streamComplete(messages)) {
    res.write(`data: ${JSON.stringify({ chunk })}\n\n`);
  }

  res.write(`data: ${JSON.stringify({ done: true })}\n\n`);
  res.end();
}
```

### 5.3 AsyncIterable dans MistralService

```typescript
public async *streamComplete(messages): AsyncIterable<string> {
  const stream = await this.client.chat.stream({ model, messages });

  for await (const event of stream) {
    const content = event.data.choices?.[0]?.delta?.content;
    if (content) {
      yield content;  // Retourne chaque morceau
    }
  }
}
```

### 5.4 CÃ´tÃ© frontend (Vue.js)

```typescript
const response = await fetch('/api/chat/stream', { method: 'POST', body });
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  const chunk = decoder.decode(value);
  const lines = chunk.split('\n');

  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const data = JSON.parse(line.substring(6));
      if (data.chunk) {
        messageContent += data.chunk;
        // Mise Ã  jour rÃ©active de l'UI
      }
    }
  }
}
```

---

## 6. Persistance avec Prisma

### 6.1 SchÃ©ma

```prisma
// src/prisma/schema.prisma

model Conversation {
  id        String    @id @default(uuid())
  userId    String?
  title     String?
  createdAt DateTime  @default(now())
  updatedAt DateTime  @updatedAt
  messages  Message[]
}

model Message {
  id             String       @id @default(uuid())
  conversationId String
  role           MessageRole  // user | assistant | system
  content        String
  createdAt      DateTime     @default(now())
  conversation   Conversation @relation(...)
}

enum MessageRole {
  user
  assistant
  system
}
```

### 6.2 ConversationService

```typescript
class ConversationService {
  // CrÃ©er une conversation
  async create(userId?: string): Promise<Conversation>;

  // Ajouter un message (avec transaction)
  async addMessage(conversationId, role, content): Promise<Message>;

  // RÃ©cupÃ©rer l'historique pour Mistral
  async getChatHistory(conversationId): Promise<ChatMessage[]>;
}
```

### 6.3 Transactions Prisma

```typescript
// Garantit l'atomicitÃ© (tout ou rien)
await this.prisma.$transaction([
  this.prisma.message.create({ data: messageData }),
  this.prisma.conversation.update({
    where: { id },
    data: { updatedAt: new Date() },
  }),
]);
```

### 6.4 Niveaux d'isolation

| Niveau          | Description                                         |
| --------------- | --------------------------------------------------- |
| ReadUncommitted | Peut lire des donnÃ©es non validÃ©es                  |
| ReadCommitted   | Ne lit que les donnÃ©es validÃ©es (dÃ©faut PostgreSQL) |
| RepeatableRead  | Lectures cohÃ©rentes dans la transaction             |
| Serializable    | Le plus strict                                      |

---

## 7. Embeddings et Recherche Vectorielle

### 7.1 Qu'est-ce qu'un Embedding ?

Un **embedding** est une reprÃ©sentation vectorielle d'un texte. Il transforme des mots/phrases en tableaux de nombres qui capturent le **sens sÃ©mantique**.

```
"Comment installer Docker ?"
        â†“ generateEmbedding()
[0.023, -0.156, 0.789, 0.034, ...] // 1024 nombres (dimension Mistral)
```

**PropriÃ©tÃ© clÃ©** : Deux textes similaires en sens auront des vecteurs proches dans l'espace.

### 7.2 GÃ©nÃ©ration d'embeddings avec Mistral

```typescript
// src/services/mistral/MistralService.ts

public async generateEmbedding(text: string): Promise<number[]> {
  const response = await this.client.embeddings.create({
    model: 'mistral-embed',
    inputs: [text],
  });
  return response.data[0].embedding; // number[1024]
}

// Version batch (plus efficace pour plusieurs textes)
public async generateEmbeddings(texts: string[]): Promise<number[][]> {
  const response = await this.client.embeddings.create({
    model: 'mistral-embed',
    inputs: texts,
  });
  return response.data.map(item => item.embedding);
}
```

### 7.3 Stockage avec pgvector

**pgvector** est une extension PostgreSQL pour stocker et rechercher des vecteurs.

```sql
-- Activer l'extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Table de documents avec embeddings
CREATE TABLE documents (
  id BIGSERIAL PRIMARY KEY,
  content TEXT,
  embedding vector(1024)  -- Type vector de dimension 1024
);

-- Index pour accÃ©lÃ©rer les recherches (optionnel mais recommandÃ©)
CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

### 7.4 Distance Cosinus

La **distance cosinus** mesure l'angle entre deux vecteurs :

| Distance  | Signification              |
| --------- | -------------------------- |
| 0         | Identiques                 |
| < 0.3     | TrÃ¨s similaires âœ…         |
| 0.3 - 0.6 | LiÃ©s au sujet âš ï¸           |
| > 0.6     | Pas vraiment pertinents âŒ |

```sql
-- OpÃ©rateur <=> pour la distance cosinus dans pgvector
SELECT content, embedding <=> '[0.1, 0.2, ...]'::vector AS distance
FROM documents
ORDER BY distance
LIMIT 5;
```

### 7.5 DocumentService

```typescript
// src/services/document/DocumentService.ts

export class DocumentService {
  // Ajouter un document (embedding gÃ©nÃ©rÃ© automatiquement)
  async addDocument(input: { content: string }): Promise<Document> {
    const embedding = await mistral.generateEmbedding(input.content);
    const embeddingStr = `[${embedding.join(',')}]`;

    // Prisma ne supporte pas nativement pgvector â†’ SQL brut
    return await this.prisma.$queryRawUnsafe(
      `INSERT INTO documents (content, embedding)
       VALUES ($1, $2::vector)
       RETURNING id, content`,
      input.content,
      embeddingStr
    );
  }

  // Recherche sÃ©mantique
  async searchSimilar(query: string, limit = 5): Promise<SearchResult[]> {
    const queryEmbedding = await mistral.generateEmbedding(query);
    const embeddingStr = `[${queryEmbedding.join(',')}]`;

    return await this.prisma.$queryRawUnsafe(
      `SELECT id, content, embedding <=> $1::vector AS distance
       FROM documents
       ORDER BY distance
       LIMIT $2`,
      embeddingStr,
      limit
    );
  }
}
```

### 7.6 Pourquoi $queryRawUnsafe ?

Prisma ne supporte pas nativement le type `vector` de pgvector. On utilise donc :

| MÃ©thode                           | SÃ©curitÃ©     | Usage                                   |
| --------------------------------- | ------------ | --------------------------------------- |
| `prisma.model.create()`           | âœ… SÃ»r       | Types standards (Conversation, Message) |
| `$queryRaw` template              | âœ… SÃ»r       | SQL paramÃ©trÃ© mais limitÃ©               |
| `$queryRawUnsafe` + `$1, $2`      | âœ… SÃ»r       | SQL avec types custom (vector)          |
| `$queryRawUnsafe` + concatÃ©nation | âŒ Dangereux | JAMAIS faire Ã§a !                       |

**Important** : On utilise des paramÃ¨tres positionnels (`$1`, `$2`) qui sont Ã©chappÃ©s par PostgreSQL, donc c'est sÃ©curisÃ©.

### 7.7 Algorithmes de recherche vectorielle

| Algorithme  | Type  | Vitesse        | PrÃ©cision | Usage           |
| ----------- | ----- | -------------- | --------- | --------------- |
| Force brute | Exact | ğŸ¢ Lent        | 100%      | Petits datasets |
| **IVFFlat** | ANN   | ğŸ‡ Rapide      | ~95%      | Bon compromis   |
| **HNSW**    | ANN   | ğŸš€ TrÃ¨s rapide | ~98%      | Production      |

**ANN** = Approximate Nearest Neighbor (sacrifice un peu de prÃ©cision pour la vitesse)

---

## 8. RAG - Retrieval-Augmented Generation

### 8.1 Concept

Le **RAG** permet Ã  un LLM de rÃ©pondre avec des **connaissances externes** (documents privÃ©s, FAQ, etc.) sans fine-tuning.

```
Question utilisateur
        â†“
1. GÃ©nÃ©rer l'embedding de la question
        â†“
2. Chercher les documents similaires en base
        â†“
3. Construire un prompt avec le contexte trouvÃ©
        â†“
4. Envoyer au LLM
        â†“
RÃ©ponse enrichie par les documents
```

### 8.2 Avantages du RAG

| Avantage                         | Description                                |
| -------------------------------- | ------------------------------------------ |
| **DonnÃ©es privÃ©es**              | Le LLM peut rÃ©pondre sur vos docs internes |
| **RÃ©duction des hallucinations** | RÃ©ponses basÃ©es sur des faits              |
| **Pas de fine-tuning**           | Moins coÃ»teux, plus simple                 |
| **Mise Ã  jour facile**           | Ajouter/retirer des docs Ã  chaud           |

### 8.3 ImplÃ©mentation

```typescript
// Exemple de flux RAG complet

async function chatWithRAG(userQuestion: string, conversationId: string) {
  const docs = getDocumentService();
  const mistral = getMistralService();
  const conversations = getConversationService();

  // 1. Chercher les documents pertinents
  const relevantDocs = await docs.searchSimilar(userQuestion, { limit: 3 });

  // 2. Construire le contexte
  const context = relevantDocs.map((doc) => doc.content).join('\n\n---\n\n');

  // 3. CrÃ©er le prompt enrichi
  const systemPrompt = `Tu es un assistant. RÃ©ponds en te basant sur ces documents :

${context}

Si l'information n'est pas dans les documents, dis-le clairement.`;

  // 4. RÃ©cupÃ©rer l'historique et ajouter le system prompt
  const history = await conversations.getChatHistory(conversationId);
  history[0] = { role: 'system', content: systemPrompt };

  // 5. Obtenir la rÃ©ponse
  return await mistral.complete(history);
}
```

### 8.4 Chunking (DÃ©coupage)

Pour les longs documents, on les dÃ©coupe en **chunks** avant de gÃ©nÃ©rer les embeddings.

**Pourquoi ?** Un seul vecteur pour un long document "dilue" le sens. Des chunks permettent une recherche plus prÃ©cise.

### 8.5 StratÃ©gies de chunking

| StratÃ©gie           | Description                | Usage                        |
| ------------------- | -------------------------- | ---------------------------- |
| **Fixed size**      | 500 caractÃ¨res             | Simple, rapide               |
| **Sentence-based**  | Par phrases                | PrÃ©serve le sens             |
| **Paragraph-based** | Par paragraphes            | Documents structurÃ©s         |
| **Overlap**         | Chevauchement entre chunks | Ã‰vite de couper des idÃ©es âœ… |
| **Semantic**        | Par similaritÃ© sÃ©mantique  | Le plus prÃ©cis, mais coÃ»teux |

### 8.6 Chunking avec Overlap (ImplÃ©mentÃ©)

Le **chevauchement (overlap)** est crucial : il permet de prÃ©server le contexte entre les chunks.

```
Document : |-------- 1200 caractÃ¨res --------|

Sans overlap :
  Chunk 1: |--- 500 ---|
  Chunk 2:             |--- 500 ---|   â† Coupure nette, perte de contexte !
  Chunk 3:                         |--- 200 ---|

Avec overlap (100 chars) :
  Chunk 1: |--- 500 ---|
  Chunk 2:        |--- 500 ---|   â† Les 100 derniers chars de Chunk 1
                                     sont les 100 premiers de Chunk 2
  Chunk 3:              |--- 500 ---|
```

**Notre implÃ©mentation** :

```typescript
// src/application/services/chunking/ChunkingService.ts

export class ChunkingService {
  /**
   * DÃ©coupe un texte en chunks avec chevauchement
   *
   * @param text - Le texte Ã  dÃ©couper
   * @param options.chunkSize - Taille max d'un chunk (dÃ©faut: 500)
   * @param options.overlap - Chevauchement entre chunks (dÃ©faut: 100)
   * @param options.separators - SÃ©parateurs pour couper proprement
   */
  chunkText(text: string, options: ChunkingOptions = {}): ChunkingResult {
    const {
      chunkSize = 500,
      overlap = 100,
      separators = ['\n\n', '\n', '. ', ' '],
    } = options;

    // Validation : l'overlap doit Ãªtre < chunkSize
    if (overlap >= chunkSize) {
      throw new Error('Overlap must be smaller than chunkSize');
    }

    const chunks: Chunk[] = [];
    let currentPosition = 0;

    while (currentPosition < text.length) {
      // 1. DÃ©finir la fin potentielle du chunk
      let endPosition = Math.min(currentPosition + chunkSize, text.length);

      // 2. Chercher un bon point de coupure (sÃ©parateur)
      if (endPosition < text.length) {
        const chunkContent = text.slice(currentPosition, endPosition);
        const splitPoint = this.findBestSplitPoint(chunkContent, separators);
        if (splitPoint > chunkSize / 2) {
          endPosition = currentPosition + splitPoint;
        }
      }

      // 3. Extraire et sauvegarder le chunk
      chunks.push({
        content: text.slice(currentPosition, endPosition).trim(),
        index: chunks.length,
        startOffset: currentPosition,
        endOffset: endPosition,
      });

      // 4. Avancer avec overlap : step = chunkSize - overlap
      currentPosition += chunkSize - overlap;
    }

    return { chunks, totalChunks: chunks.length, originalLength: text.length };
  }

  private findBestSplitPoint(text: string, separators: string[]): number {
    // Cherche le dernier sÃ©parateur de haute prioritÃ©
    for (const separator of separators) {
      const lastIndex = text.lastIndexOf(separator);
      if (lastIndex !== -1) return lastIndex + separator.length;
    }
    return -1;
  }
}
```

**Endpoint API** :

```bash
# POST /api/documents/chunked
curl -X POST http://localhost:3000/api/documents/chunked \
  -H "Content-Type: application/json" \
  -d '{
    "content": "TrÃ¨s long document de 5000 mots...",
    "chunkSize": 500,
    "overlap": 100
  }'

# RÃ©ponse :
{
  "message": "Document split into 12 chunks",
  "sourceId": 27,                          # ID du document source (original)
  "totalChunks": 12,
  "originalLength": 5000,
  "documents": [
    { "id": 28, "sourceId": 27, "chunkIndex": 0, "contentPreview": "..." },
    { "id": 29, "sourceId": 27, "chunkIndex": 1, "contentPreview": "..." },
    ...
  ],
  "chunks": [...]
}
```

**Tracking des chunks en base de donnÃ©es** :

```sql
-- Structure de la table documents avec tracking
SELECT id, LEFT(content, 30), source_id, chunk_index, embedding IS NOT NULL
FROM documents WHERE id >= 27;

 id |           left           | source_id | chunk_index | has_embedding
----+--------------------------+-----------+-------------+---------------
 27 | Le machine learning est  |     NULL  |        NULL | false  -- Document source
 28 | Le machine learning est  |        27 |           0 | true   -- Chunk 0
 29 | Les algorithmes de ML... |        27 |           1 | true   -- Chunk 1
 30 | Le deep learning est...  |        27 |           2 | true   -- Chunk 2
```

**Suppression en cascade** : Supprimer le document source (id=27) supprime automatiquement tous ses chunks grÃ¢ce Ã  `ON DELETE CASCADE`.

```bash
curl -X DELETE http://localhost:3000/api/documents/27
# â†’ Les documents 28, 29, 30 sont automatiquement supprimÃ©s
```

**Calcul du step** :

```
step = chunkSize - overlap = 500 - 100 = 400

Document de 1200 caractÃ¨res :
  Chunk 1 : position 0 â†’ 500 (500 chars)
  Chunk 2 : position 400 â†’ 900 (500 chars)
  Chunk 3 : position 800 â†’ 1200 (400 chars)

Estimation : ceil((1200 - 100) / 400) = ceil(2.75) = 3 chunks
```

**Avantages de l'overlap** :

| Avantage                     | Explication                                                |
| ---------------------------- | ---------------------------------------------------------- |
| **PrÃ©servation du contexte** | Une phrase coupÃ©e en deux sera complÃ¨te dans un des chunks |
| **Meilleure recherche**      | Plus de chances de retrouver l'info pertinente             |
| **CohÃ©rence sÃ©mantique**     | Les embeddings captent mieux le sens                       |
| **CoÃ»t minimal**             | ~20% de tokens en plus, mais qualitÃ© bien meilleure        |

### 8.7 ModÃ¨les d'embedding

| ModÃ¨le                   | Fournisseur | Dimension | CoÃ»t             |
| ------------------------ | ----------- | --------- | ---------------- |
| `mistral-embed`          | Mistral     | 1024      | ~0.1â‚¬/1M tokens  |
| `text-embedding-3-small` | OpenAI      | 1536      | ~0.02$/1M tokens |
| `text-embedding-3-large` | OpenAI      | 3072      | ~0.13$/1M tokens |
| `all-MiniLM-L6-v2`       | Open source | 384       | Gratuit (local)  |
| `nomic-embed-text`       | Open source | 768       | Gratuit (local)  |

### 8.8 Le System Prompt est rÃ©Ã©crit Ã  chaque message

**Point clÃ©** : Le system prompt n'est pas statique. Il est **enrichi dynamiquement** Ã  chaque nouveau message avec les documents pertinents pour cette question spÃ©cifique.

```typescript
// Ã€ CHAQUE message de l'utilisateur :

// 1. RÃ©cupÃ©rer l'historique (avec le system prompt original)
const chatHistory = await conversationService.getChatHistory(conversationId);
// chatHistory[0] = { role: 'system', content: 'Tu es un assistant...' }

// 2. Construire un NOUVEAU system prompt basÃ© sur la question
const ragContext = await ragService.buildEnrichedPrompt(message);
// ragContext.enrichedPrompt = 'Tu es un assistant... [Document 1] WiFi = Secret123...'

// 3. REMPLACER le system prompt original
chatHistory[0].content = ragContext.enrichedPrompt;

// 4. Envoyer Ã  Mistral avec le nouveau contexte
mistralClient.streamComplete(chatHistory);
```

**Pourquoi ?** Chaque question peut nÃ©cessiter des documents diffÃ©rents :

```
Message 1 : "Salut !"
  â†’ RAG cherche docs pour "Salut" â†’ Rien de pertinent
  â†’ System prompt = basique

Message 2 : "C'est quoi le WiFi ?"
  â†’ RAG cherche docs pour "WiFi" â†’ Trouve le doc WiFi !
  â†’ System prompt = enrichi avec infos WiFi

Message 3 : "Et les horaires ?"
  â†’ RAG cherche docs pour "horaires" â†’ Trouve le doc horaires !
  â†’ System prompt = enrichi avec infos horaires (diffÃ©rent !)
```

**Note** : L'enrichissement est fait **Ã  la volÃ©e**. Le system prompt original en base de donnÃ©es n'est jamais modifiÃ©.

### 8.9 Exemple complet de requÃªte Mistral avec RAG

Voici exactement ce qui est envoyÃ© Ã  l'API Mistral quand le RAG trouve un document :

**ScÃ©nario** : L'utilisateur demande "C'est quoi le mot de passe WiFi ?" et un document existe en base avec cette info.

```json
{
  "model": "mistral-tiny",
  "temperature": 0.7,
  "stream": true,
  "messages": [
    {
      "role": "system",
      "content": "Tu es un assistant IA amical et serviable. Tu rÃ©ponds en franÃ§ais de maniÃ¨re concise et utile.\n\nTu as accÃ¨s aux documents suivants pour t'aider Ã  rÃ©pondre :\n\n[Document 1]\nLe mot de passe WiFi du bureau est SuperSecret123. Le rÃ©seau s'appelle BureauNet.\n\nInstructions :\n- Utilise ces documents pour rÃ©pondre si pertinent\n- Si l'information n'est pas dans les documents, utilise tes connaissances gÃ©nÃ©rales\n- Ne mentionne pas explicitement \"selon les documents\" sauf si l'utilisateur le demande"
    },
    {
      "role": "user",
      "content": "Salut !"
    },
    {
      "role": "assistant",
      "content": "Bonjour ! Comment puis-je t'aider ?"
    },
    {
      "role": "user",
      "content": "C'est quoi le mot de passe WiFi ?"
    }
  ]
}
```

**Points importants** :

- Le contenu du document est **littÃ©ralement copiÃ©** dans le system prompt
- L'**historique complet** de conversation est envoyÃ©
- Le RAG est basÃ© sur la **derniÃ¨re question** uniquement
- Mistral "voit" les documents comme du texte normal dans le system prompt

**RÃ©ponse de Mistral** :

```json
{
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "Le mot de passe WiFi est SuperSecret123 et le rÃ©seau s'appelle BureauNet."
      }
    }
  ]
}
```

### 8.9 CoÃ»t du RAG

Le RAG consomme des tokens supplÃ©mentaires car les documents sont envoyÃ©s Ã  chaque requÃªte :

| Composant                   | Tokens (exemple) |
| --------------------------- | ---------------- |
| System prompt de base       | ~50              |
| Documents injectÃ©s (3 docs) | ~300-500         |
| Historique conversation     | ~200             |
| Question utilisateur        | ~20              |
| **Total entrÃ©e**            | **~600-800**     |
| RÃ©ponse                     | ~100             |

**CoÃ»t approximatif** : ~0.001â‚¬ par message avec RAG (mistral-tiny)

---

## 9. Architecture Clean Architecture

Le projet utilise une **Clean Architecture** (aussi appelÃ©e Hexagonal Architecture ou Ports & Adapters) pour une meilleure sÃ©paration des responsabilitÃ©s et testabilitÃ©.

### 9.1 Les couches

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INFRASTRUCTURE                            â”‚
â”‚  (HTTP, Base de donnÃ©es, APIs externes)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        APPLICATION                         â”‚  â”‚
â”‚  â”‚  (Use Cases, Services, Ports)                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚                      DOMAIN                          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  (EntitÃ©s, Value Objects, RÃ¨gles mÃ©tier)            â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**RÃ¨gle de dÃ©pendance** : Les couches internes ne connaissent pas les couches externes.

### 9.2 Structure des fichiers

```
src/
â”œâ”€â”€ domain/                          # ğŸŸ¢ COUCHE DOMAINE (cÅ“ur mÃ©tier)
â”‚   â”œâ”€â”€ conversation/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â”œâ”€â”€ Conversation.ts      # EntitÃ© Conversation
â”‚   â”‚   â”‚   â””â”€â”€ Message.ts           # EntitÃ© Message
â”‚   â”‚   â”œâ”€â”€ errors/
â”‚   â”‚   â”‚   â””â”€â”€ ConversationErrors.ts
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â””â”€â”€ IConversationRepository.ts  # Interface (port)
â”‚   â”‚   â””â”€â”€ valueObjects/
â”‚   â”‚       â””â”€â”€ MessageRole.ts
â”‚   â”œâ”€â”€ document/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â””â”€â”€ Document.ts
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â””â”€â”€ IDocumentRepository.ts
â”‚   â”‚   â””â”€â”€ valueObjects/
â”‚   â”‚       â””â”€â”€ Embedding.ts
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ errors/
â”‚       â”‚   â””â”€â”€ DomainError.ts
â”‚       â””â”€â”€ valueObjects/
â”‚           â””â”€â”€ UUID.ts
â”‚
â”œâ”€â”€ application/                     # ğŸ”µ COUCHE APPLICATION (orchestration)
â”‚   â”œâ”€â”€ ports/
â”‚   â”‚   â”œâ”€â”€ in/                      # Ports d'entrÃ©e (ce que l'app expose)
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation.ts      # Interfaces des use cases
â”‚   â”‚   â”‚   â””â”€â”€ document.ts
â”‚   â”‚   â””â”€â”€ out/                     # Ports de sortie (ce dont l'app a besoin)
â”‚   â”‚       â”œâ”€â”€ IConversationService.ts
â”‚   â”‚       â”œâ”€â”€ IDocumentService.ts
â”‚   â”‚       â”œâ”€â”€ IMistralClient.ts
â”‚   â”‚       â””â”€â”€ IRAGService.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ conversation/
â”‚   â”‚   â”‚   â””â”€â”€ ConversationService.ts
â”‚   â”‚   â”œâ”€â”€ document/
â”‚   â”‚   â”‚   â””â”€â”€ DocumentService.ts
â”‚   â”‚   â””â”€â”€ rag/
â”‚   â”‚       â””â”€â”€ RAGService.ts        # Service RAG
â”‚   â””â”€â”€ usecases/
â”‚       â”œâ”€â”€ conversation/
â”‚       â”‚   â”œâ”€â”€ CreateConversationUseCase.ts
â”‚       â”‚   â”œâ”€â”€ SendMessageUseCase.ts
â”‚       â”‚   â””â”€â”€ StreamMessageUseCase.ts  # Use case principal du chat
â”‚       â””â”€â”€ document/
â”‚           â”œâ”€â”€ AddDocumentUseCase.ts
â”‚           â”œâ”€â”€ SearchDocumentsUseCase.ts
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ infrastructure/                  # ğŸ”´ COUCHE INFRASTRUCTURE (dÃ©tails techniques)
â”‚   â”œâ”€â”€ http/
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â”œâ”€â”€ conversationController.ts
â”‚   â”‚   â”‚   â””â”€â”€ documentController.ts
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ conversationRoutes.ts
â”‚   â”‚   â”‚   â””â”€â”€ documentRoutes.ts
â”‚   â”‚   â””â”€â”€ middlewares/
â”‚   â”‚       â””â”€â”€ errorHandler.ts
â”‚   â”œâ”€â”€ persistence/
â”‚   â”‚   â”œâ”€â”€ ConversationRepository.ts  # ImplÃ©mente IConversationRepository
â”‚   â”‚   â””â”€â”€ DocumentRepository.ts      # ImplÃ©mente IDocumentRepository
â”‚   â”œâ”€â”€ external/
â”‚   â”‚   â””â”€â”€ mistral/
â”‚   â”‚       â”œâ”€â”€ MistralClient.ts       # ImplÃ©mente IMistralClient
â”‚   â”‚       â”œâ”€â”€ tokenizer.ts
â”‚   â”‚       â””â”€â”€ errors.ts
â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â””â”€â”€ retry.ts                   # Exponential backoff
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ prisma.ts
â”‚
â””â”€â”€ server.ts                        # Point d'entrÃ©e
```

### 9.3 ResponsabilitÃ©s par couche

| Couche             | Contient                                  | ResponsabilitÃ©                                 |
| ------------------ | ----------------------------------------- | ---------------------------------------------- |
| **Domain**         | Entities, Value Objects, Interfaces repos | RÃ¨gles mÃ©tier pures, aucune dÃ©pendance externe |
| **Application**    | Use Cases, Services, Ports                | Orchestrer les cas d'utilisation               |
| **Infrastructure** | Controllers, Repositories, Clients API    | ImplÃ©menter les dÃ©tails techniques             |

### 9.4 Les Ports (Interfaces)

Les **ports** dÃ©finissent des contrats que l'infrastructure doit respecter :

```typescript
// application/ports/out/IMistralClient.ts
export interface IMistralClient {
  chat(message: string, options?: ChatOptions): Promise<string | null>;
  streamComplete(messages: ChatMessage[]): AsyncIterable<string>;
  generateEmbedding(text: string): Promise<number[]>;
}

// infrastructure/external/mistral/MistralClient.ts
export class MistralClient implements IMistralClient {
  // ImplÃ©mentation concrÃ¨te avec le SDK Mistral
}
```

**Avantage** : On peut remplacer `MistralClient` par un mock pour les tests !

### 9.5 Les Use Cases

Un **Use Case** reprÃ©sente une action mÃ©tier unique :

```typescript
// application/usecases/conversation/StreamMessageUseCase.ts

export class StreamMessageUseCase {
  constructor(
    private conversationService: IConversationService,
    private mistralClient: IMistralClient,
    private ragService: IRAGService,  // Injection de dÃ©pendances
  ) {}

  async *execute(input: StreamMessageInput): AsyncGenerator<StreamMessageChunk> {
    // 1. Sauvegarder le message
    await this.conversationService.addMessage(...);

    // 2. RÃ©cupÃ©rer l'historique
    const chatHistory = await this.conversationService.getChatHistory(...);

    // 3. Enrichir avec RAG
    const ragContext = await this.ragService.buildEnrichedPrompt(message);
    chatHistory[0].content = ragContext.enrichedPrompt;

    // 4. Streamer la rÃ©ponse
    for await (const chunk of this.mistralClient.streamComplete(chatHistory)) {
      yield { chunk };
    }
  }
}
```

### 9.6 Flux d'une requÃªte (Clean Architecture)

```
POST /api/chat/stream
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INFRASTRUCTURE: conversationController.ts                       â”‚
â”‚   â†’ Valide la requÃªte HTTP                                      â”‚
â”‚   â†’ Appelle le Use Case                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ APPLICATION: StreamMessageUseCase.ts                            â”‚
â”‚   â†’ Orchestre la logique mÃ©tier                                 â”‚
â”‚   â†’ Utilise les Services via leurs interfaces (ports)          â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â”€ ConversationService.addMessage()                          â”‚
â”‚   â”œâ”€â”€ ConversationService.getChatHistory()                      â”‚
â”‚   â”œâ”€â”€ RAGService.buildEnrichedPrompt()  â—„â”€â”€ Recherche docs     â”‚
â”‚   â””â”€â”€ MistralClient.streamComplete()                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INFRASTRUCTURE: ImplÃ©mentations concrÃ¨tes                       â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â”€ ConversationRepository (Prisma + PostgreSQL)              â”‚
â”‚   â”œâ”€â”€ DocumentRepository (pgvector)                             â”‚
â”‚   â””â”€â”€ MistralClient (SDK Mistral)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXTERNAL: APIs et Base de donnÃ©es                               â”‚
â”‚   â”œâ”€â”€ Mistral AI API                                            â”‚
â”‚   â””â”€â”€ PostgreSQL + pgvector                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.7 Avantages de cette architecture

| Avantage           | Description                                   |
| ------------------ | --------------------------------------------- |
| **TestabilitÃ©**    | On peut mocker les dÃ©pendances externes       |
| **MaintenabilitÃ©** | Chaque couche a une responsabilitÃ© claire     |
| **FlexibilitÃ©**    | Changer de DB ou d'API sans toucher au mÃ©tier |
| **IndÃ©pendance**   | Le domaine ne dÃ©pend de rien                  |

---

## 10. Frontend Vue.js

### 10.1 Composants

```
frontend/src/
â”œâ”€â”€ views/
â”‚   â””â”€â”€ ChatBot.vue           # Vue principale
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatInput.vue         # Champ de saisie
â”‚   â”œâ”€â”€ ChatMessage.vue       # Bulle de message
â”‚   â””â”€â”€ ChatSidebar.vue       # Liste des conversations
â””â”€â”€ router/
    â””â”€â”€ index.ts              # Vue Router
```

### 10.2 Gestion du streaming

```vue
<script setup>
const messages = ref([]);

async function sendMessage(content) {
  // 1. Ajouter le message user
  messages.value.push({ role: 'user', content });

  // 2. PrÃ©parer le message assistant (vide)
  const assistantIndex = messages.value.length;
  messages.value.push({ role: 'assistant', content: '' });

  // 3. Stream la rÃ©ponse
  const reader = response.body.getReader();
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    // 4. Mettre Ã  jour en temps rÃ©el
    messages.value[assistantIndex].content += chunk;
  }
}
</script>
```

---

## 11. Concepts clÃ©s Ã  retenir

### 11.1 Patterns

| Pattern                  | OÃ¹                           | Pourquoi                               |
| ------------------------ | ---------------------------- | -------------------------------------- |
| **Clean Architecture**   | Structure du projet          | SÃ©paration des responsabilitÃ©s         |
| **Ports & Adapters**     | Interfaces + ImplÃ©mentations | DÃ©couplage, testabilitÃ©                |
| **Use Case**             | StreamMessageUseCase         | Une action mÃ©tier = une classe         |
| **Dependency Injection** | Constructeurs Use Cases      | Injecter les dÃ©pendances (mocks)       |
| **Repository**           | ConversationRepository       | Abstraction de la persistance          |
| **Singleton**            | getMistralClient()           | Une seule instance, config partagÃ©e    |
| **AsyncIterator**        | streamComplete()             | Traiter les donnÃ©es au fur et Ã  mesure |
| **Exponential Backoff**  | withRetry()                  | RÃ©silience aux erreurs API             |
| **Sliding Window**       | tokenizer.ts                 | GÃ©rer les limites de contexte          |
| **RAG**                  | RAGService                   | Enrichir le LLM avec des docs privÃ©s   |

### 11.2 Bonnes pratiques

1. **SÃ©paration des responsabilitÃ©s** : Routes â†’ Controllers â†’ Services
2. **Typage fort** : Interfaces TypeScript partout
3. **Gestion des erreurs** : Classes d'erreurs custom
4. **Configuration** : Variables d'environnement, pas de hardcode
5. **Logging** : Console.log pour debug, avec prÃ©fixes `[ServiceName]`
6. **ParamÃ¨tres SQL** : Toujours utiliser `$1, $2` au lieu de concatÃ©nation

### 11.3 Points de vigilance

| ProblÃ¨me                 | Solution                       |
| ------------------------ | ------------------------------ |
| Rate limiting (429)      | Retry avec exponential backoff |
| Context overflow (400)   | Sliding window                 |
| Latence UX               | Streaming SSE                  |
| Perte de contexte        | Persistance PostgreSQL         |
| Erreurs silencieuses     | Classes d'erreurs typÃ©es       |
| Longs documents          | Chunking avant embedding       |
| RÃ©sultats non pertinents | Filtrer par maxDistance        |

### 11.4 Commandes utiles

```bash
# GÃ©nÃ©rer le client Prisma
pnpm prisma:generate

# Pousser le schÃ©ma en DB
pnpm db:push

# Reset la DB
pnpm db:push --force-reset

# Migrations SQL personnalisÃ©es (pour pgvector)
docker compose exec app sh -c "cd /app/src && pnpm migrate"

# Logs Docker
docker compose logs app --tail=20
docker compose logs frontend --tail=20

# Activer pgvector
docker compose exec postgres psql -U postgres -d ia_chat -c "CREATE EXTENSION IF NOT EXISTS vector;"

# Voir les documents indexÃ©s (avec tracking des chunks)
docker compose exec postgres psql -U postgres -d ia_chat -c "SELECT id, LEFT(content, 50), source_id, chunk_index FROM documents;"

# Voir les migrations appliquÃ©es
docker compose exec postgres psql -U postgres -d ia_chat -c "SELECT * FROM _migrations;"
```

### 11.5 SystÃ¨me de migrations SQL

Prisma ne supporte pas le type `vector` de pgvector, donc on utilise un systÃ¨me de migrations SQL personnalisÃ© :

```
src/migrations/
â”œâ”€â”€ 001_create_documents_table.sql   # Table de base
â”œâ”€â”€ 002_add_chunk_tracking.sql       # Colonnes source_id, chunk_index
â””â”€â”€ migrate.ts                       # Script d'exÃ©cution
```

**Structure de la table `_migrations`** :

| id  | name                           | applied_at |
| --- | ------------------------------ | ---------- |
| 1   | 001_create_documents_table.sql | 2024-12-21 |
| 2   | 002_add_chunk_tracking.sql     | 2024-12-21 |

**CrÃ©er une nouvelle migration** :

```sql
-- src/migrations/003_add_my_feature.sql
ALTER TABLE documents ADD COLUMN IF NOT EXISTS my_column TEXT;
```

Puis exÃ©cuter : `docker compose exec app sh -c "cd /app/src && pnpm migrate"`

### 11.6 Fixtures et Seeding

Pour tester l'application avec des donnÃ©es rÃ©alistes :

```bash
# Voir ce qui serait insÃ©rÃ© (sans exÃ©cuter)
docker compose exec app sh -c "cd /app/src && pnpm seed:dry"

# InsÃ©rer les fixtures (conserve les donnÃ©es existantes)
docker compose exec app sh -c "cd /app/src && pnpm seed"

# Nettoyer et rÃ©insÃ©rer (reset complet)
docker compose exec app sh -c "cd /app/src && pnpm seed:clean"
```

**Structure des fixtures** :

```
src/fixtures/
â”œâ”€â”€ documents.ts   # DonnÃ©es de test (FAQ, procÃ©dures, docs techniques)
â”œâ”€â”€ seed.ts        # Script d'exÃ©cution
â””â”€â”€ index.ts       # Exports
```

**Types de documents inclus** :

| CatÃ©gorie       | Exemples                  | Chunking       |
| --------------- | ------------------------- | -------------- |
| Infos pratiques | WiFi, horaires, contacts  | Non            |
| ProcÃ©dures      | CongÃ©s, notes de frais    | Non            |
| Technique       | Docker, Architecture, API | Oui (3 chunks) |
| FAQ             | Questions frÃ©quentes      | Non            |
| RH              | TÃ©lÃ©travail               | Non            |

**Exemple de fixture** :

```typescript
// src/fixtures/documents.ts
export const documentFixtures: DocumentFixture[] = [
  {
    title: 'WiFi et RÃ©seau',
    content: `Le mot de passe WiFi est SecretWifi2024!...`,
    useChunking: false, // Document court â†’ pas de chunking
  },
  {
    title: 'Guide Docker',
    content: `Guide complet de 800 mots...`,
    useChunking: true, // Document long â†’ chunking
    chunkSize: 400,
    overlap: 80,
  },
];
```

---

## ğŸ“ Checklist de rÃ©vision

### Clean Architecture

- [ ] Je connais les 3 couches : Domain, Application, Infrastructure
- [ ] Je comprends la rÃ¨gle de dÃ©pendance (vers l'intÃ©rieur)
- [ ] Je sais ce qu'est un Port (interface) et pourquoi c'est utile
- [ ] Je sais ce qu'est un Use Case et son rÃ´le
- [ ] Je comprends l'injection de dÃ©pendances

### Patterns

- [ ] Je comprends le pattern Singleton
- [ ] Je sais implÃ©menter un retry avec exponential backoff
- [ ] Je comprends pourquoi le jitter est important
- [ ] Je sais ce qu'est une sliding window et pourquoi c'est nÃ©cessaire

### Streaming & Frontend

- [ ] Je peux expliquer le flux SSE (Server-Sent Events)
- [ ] Je comprends les AsyncIterables (`async *` et `yield`)
- [ ] Je peux consommer un stream cÃ´tÃ© frontend

### Base de donnÃ©es

- [ ] Je sais crÃ©er un schÃ©ma Prisma
- [ ] Je comprends les transactions et niveaux d'isolation
- [ ] Je sais utiliser `$queryRawUnsafe` avec des paramÃ¨tres positionnels
- [ ] Je sais crÃ©er des migrations SQL pour les types non supportÃ©s par Prisma (vector)

### Embeddings & RAG

- [ ] Je comprends ce qu'est un embedding (texte â†’ vecteur)
- [ ] Je sais gÃ©nÃ©rer un embedding avec `mistral-embed`
- [ ] Je comprends la distance cosinus et comment l'interprÃ©ter
- [ ] Je sais stocker des vecteurs avec pgvector
- [ ] Je peux implÃ©menter une recherche sÃ©mantique
- [ ] Je comprends le concept de RAG et son utilitÃ©
- [ ] Je sais que le system prompt est rÃ©Ã©crit Ã  chaque message avec le contexte RAG
- [ ] Je sais pourquoi le chunking est important pour les longs documents
- [ ] Je comprends le chunking avec overlap et pourquoi c'est mieux que sans
- [ ] Je sais calculer le step : `step = chunkSize - overlap`
- [ ] Je connais les algorithmes de recherche vectorielle (Force brute, IVFFlat, HNSW)

---

_Document mis Ã  jour le 21/12/2024_
