# ğŸ“š RÃ©vision - IntÃ©gration IA avec Node.js

> RÃ©capitulatif technique de l'intÃ©gration de Mistral AI dans une application Node.js/Express avec Vue.js

---

## ğŸ“‹ Table des matiÃ¨res

1. [Architecture globale](#1-architecture-globale)
2. [MistralService - Le cÅ“ur de l'IA](#2-mistralservice---le-cÅ“ur-de-lia)
3. [Robustesse - Retry avec Exponential Backoff](#3-robustesse---retry-avec-exponential-backoff)
4. [Gestion du Contexte - Sliding Window](#4-gestion-du-contexte---sliding-window)
5. [Streaming avec SSE](#5-streaming-avec-sse)
6. [Persistance avec Prisma](#6-persistance-avec-prisma)
7. [Embeddings et Recherche Vectorielle](#7-embeddings-et-recherche-vectorielle)
8. [RAG - Retrieval-Augmented Generation](#8-rag---retrieval-augmented-generation)
9. [Architecture MVC](#9-architecture-mvc)
10. [Frontend Vue.js](#10-frontend-vuejs)
11. [Concepts clÃ©s Ã  retenir](#11-concepts-clÃ©s-Ã -retenir)

---

## 1. Architecture globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND (Vue.js)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ChatBot    â”‚  â”‚  Documents  â”‚  â”‚  Vue Router             â”‚  â”‚
â”‚  â”‚  View       â”‚  â”‚  View (RAG) â”‚  â”‚  /chat, /documents      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ HTTP / SSE
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BACKEND (Node.js/Express)                â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        ROUTES                             â”‚   â”‚
â”‚  â”‚  POST /api/chat          POST /api/conversations          â”‚   â”‚
â”‚  â”‚  POST /api/chat/stream   GET  /api/documents              â”‚   â”‚
â”‚  â”‚  POST /api/documents     POST /api/documents/search       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     CONTROLLERS                           â”‚   â”‚
â”‚  â”‚  conversationController    documentController             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                       SERVICES                            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ MistralService  â”‚  â”‚Conversation â”‚  â”‚ Document     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ - chat()        â”‚  â”‚Service      â”‚  â”‚ Service      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ - complete()    â”‚  â”‚- create()   â”‚  â”‚- addDocument â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ - streamCompleteâ”‚  â”‚- addMessage â”‚  â”‚- searchSimilarâ”‚ â”‚   â”‚
â”‚  â”‚  â”‚ - generateEmbed â”‚  â”‚- getHistory â”‚  â”‚- (RAG)       â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        UTILS                              â”‚   â”‚
â”‚  â”‚  retry.ts (Exponential Backoff)                          â”‚   â”‚
â”‚  â”‚  tokenizer.ts (Sliding Window)                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MISTRAL AI API      â”‚    â”‚     POSTGRESQL          â”‚
â”‚  - Chat (mistral-tiny)  â”‚    â”‚  - Prisma ORM           â”‚
â”‚  - Embeddings           â”‚    â”‚  - pgvector (RAG)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. MistralService - Le cÅ“ur de l'IA

### 2.1 Structure du service

```typescript
// src/services/mistral/MistralService.ts

export class MistralService {
  private readonly client: Mistral; // SDK Mistral
  private readonly defaultModel: string; // ex: 'mistral-tiny'
  private readonly defaultTemperature: number; // ex: 0.7
  private readonly retryOptions: RetryOptions; // Config retry

  constructor(config: MistralConfig = {}) {
    // Initialisation avec API key depuis env ou config
  }
}
```

### 2.2 MÃ©thodes principales

| MÃ©thode                             | Description           | Retour                  |
| ----------------------------------- | --------------------- | ----------------------- |
| `chat(message, options)`            | Message simple        | `Promise<string>`       |
| `chatJSON<T>(message, options)`     | RÃ©ponse JSON typÃ©e    | `Promise<T>`            |
| `complete(messages, options)`       | Conversation complÃ¨te | `Promise<string>`       |
| `streamComplete(messages, options)` | Streaming             | `AsyncIterable<string>` |
| `streamChat(message, options)`      | Streaming simple      | `AsyncIterable<string>` |

### 2.3 Options disponibles

```typescript
interface ChatOptions {
  model?: string; // ModÃ¨le Ã  utiliser
  systemPrompt?: string; // Prompt systÃ¨me
  temperature?: number; // CrÃ©ativitÃ© (0-1)
  maxTokens?: number; // Limite de tokens en sortie
  jsonMode?: boolean; // Forcer rÃ©ponse JSON
  autoTruncate?: boolean; // Sliding window auto
  reservedForResponse?: number; // Tokens rÃ©servÃ©s pour rÃ©ponse
}
```

### 2.4 Pattern Singleton

```typescript
// RÃ©cupÃ©rer l'instance unique
const mistral = getMistralService();

// Reset pour les tests
resetMistralService();
```

**Pourquoi ?** Ã‰vite de crÃ©er plusieurs clients, partage la configuration.

---

## 3. Robustesse - Retry avec Exponential Backoff

### 3.1 Le problÃ¨me

Les API d'IA sont **fragiles** :

- `429` Too Many Requests (rate limit)
- `500/502/503/504` Erreurs serveur
- `ECONNRESET` Connexion coupÃ©e

### 3.2 La solution : Exponential Backoff

```
Tentative 1 â†’ Ã‰chec (429)
    â†“ Attendre 1s
Tentative 2 â†’ Ã‰chec (503)
    â†“ Attendre 2s
Tentative 3 â†’ Ã‰chec (500)
    â†“ Attendre 4s
Tentative 4 â†’ SuccÃ¨s âœ…
```

### 3.3 ImplÃ©mentation

```typescript
// src/utils/retry.ts

export async function withRetry<T>(
  fn: () => Promise<T>,
  options: RetryOptions = {}
): Promise<T> {
  const { maxRetries = 3, baseDelay = 1000, multiplier = 2 } = options;

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      if (attempt >= maxRetries || !shouldRetry(error)) {
        throw error;
      }
      const delay = baseDelay * Math.pow(multiplier, attempt);
      await sleep(delay);
    }
  }
}
```

### 3.4 Jitter (variation alÃ©atoire)

```typescript
// Ã‰vite le "thundering herd" (tous les clients retentent en mÃªme temps)
const jitter = exponentialDelay * 0.25 * (Math.random() * 2 - 1);
const finalDelay = exponentialDelay + jitter;
```

### 3.5 Configuration

| ParamÃ¨tre    | DÃ©faut  | Description              |
| ------------ | ------- | ------------------------ |
| `maxRetries` | 3       | Nombre max de tentatives |
| `baseDelay`  | 1000ms  | DÃ©lai initial            |
| `multiplier` | 2       | Facteur d'augmentation   |
| `maxDelay`   | 30000ms | DÃ©lai max (30s)          |

### 3.6 Erreurs retryables

```typescript
const RETRYABLE_STATUS_CODES = [429, 500, 502, 503, 504];
const RETRYABLE_NETWORK_ERRORS = ['ECONNRESET', 'ETIMEDOUT', 'ECONNREFUSED'];
```

---

## 4. Gestion du Contexte - Sliding Window

### 4.1 Le problÃ¨me

Chaque modÃ¨le a une **limite de contexte** :

| ModÃ¨le               | Limite         |
| -------------------- | -------------- |
| mistral-tiny         | 32 000 tokens  |
| mistral-large-latest | 128 000 tokens |
| GPT-4o               | 128 000 tokens |

Si dÃ©passÃ© â†’ Erreur `400 Bad Request - Context Length Exceeded`

### 4.2 La solution : Sliding Window

```
AVANT (50 messages, ~35000 tokens)
[System] Tu es un assistant...
[User] Message 1
[Assistant] RÃ©ponse 1
[User] Message 2
...
[User] Message 50        â† DÃ©passe la limite !

APRÃˆS (sliding window)
[System] Tu es un assistant...  â† TOUJOURS gardÃ©
[User] Message 35               â† Messages rÃ©cents
[Assistant] RÃ©ponse 35
...
[User] Message 50               â† OK, ~28000 tokens
```

### 4.3 Estimation des tokens

```typescript
// Approximation : 1 token â‰ˆ 3.5 caractÃ¨res
export function estimateTokens(text: string): number {
  const charCount = text.length;
  const tokenEstimate = Math.ceil(charCount / 3.5);
  return tokenEstimate + 4; // +4 pour overhead
}
```

### 4.4 Algorithme

```typescript
export function applySlidingWindow(
  messages: ChatMessage[],
  config: SlidingWindowConfig
): ChatMessage[] {
  // 1. SÃ©parer le system prompt
  // 2. Parcourir du plus rÃ©cent au plus ancien
  // 3. Ajouter tant qu'on reste sous le budget
  // 4. Remettre le system prompt en premier
}
```

### 4.5 RÃ¨gles

| RÃ¨gle                  | Valeur | Raison                              |
| ---------------------- | ------ | ----------------------------------- |
| `preserveSystemPrompt` | true   | Le contexte de base est crucial     |
| `reservedForResponse`  | 1000   | Laisser de la place pour la rÃ©ponse |
| `minMessages`          | 2      | Garder un minimum de contexte       |

### 4.6 IntÃ©gration automatique

```typescript
// Dans MistralService, c'est automatique !
public async complete(messages, options) {
  const { autoTruncate = true } = options;

  if (autoTruncate) {
    messages = applySlidingWindow(messages, {
      maxTokens: getModelContextLimit(model),
      reservedForResponse: 1000,
    });
  }
  // ...
}
```

---

## 5. Streaming avec SSE

### 5.1 Pourquoi le streaming ?

| Sans streaming                          | Avec streaming                         |
| --------------------------------------- | -------------------------------------- |
| Attendre 5-10s pour la rÃ©ponse complÃ¨te | Voir les mots apparaÃ®tre en temps rÃ©el |
| UX frustrante                           | UX fluide comme ChatGPT                |

### 5.2 Server-Sent Events (SSE)

**CÃ´tÃ© serveur :**

```typescript
// conversationController.ts
export async function chat(req: Request, res: Response) {
  // Headers SSE
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');
  res.flushHeaders();

  // Stream les chunks
  for await (const chunk of mistral.streamComplete(messages)) {
    res.write(`data: ${JSON.stringify({ chunk })}\n\n`);
  }

  res.write(`data: ${JSON.stringify({ done: true })}\n\n`);
  res.end();
}
```

### 5.3 AsyncIterable dans MistralService

```typescript
public async *streamComplete(messages): AsyncIterable<string> {
  const stream = await this.client.chat.stream({ model, messages });

  for await (const event of stream) {
    const content = event.data.choices?.[0]?.delta?.content;
    if (content) {
      yield content;  // Retourne chaque morceau
    }
  }
}
```

### 5.4 CÃ´tÃ© frontend (Vue.js)

```typescript
const response = await fetch('/api/chat/stream', { method: 'POST', body });
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  const chunk = decoder.decode(value);
  const lines = chunk.split('\n');

  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const data = JSON.parse(line.substring(6));
      if (data.chunk) {
        messageContent += data.chunk;
        // Mise Ã  jour rÃ©active de l'UI
      }
    }
  }
}
```

---

## 6. Persistance avec Prisma

### 6.1 SchÃ©ma

```prisma
// src/prisma/schema.prisma

model Conversation {
  id        String    @id @default(uuid())
  userId    String?
  title     String?
  createdAt DateTime  @default(now())
  updatedAt DateTime  @updatedAt
  messages  Message[]
}

model Message {
  id             String       @id @default(uuid())
  conversationId String
  role           MessageRole  // user | assistant | system
  content        String
  createdAt      DateTime     @default(now())
  conversation   Conversation @relation(...)
}

enum MessageRole {
  user
  assistant
  system
}
```

### 6.2 ConversationService

```typescript
class ConversationService {
  // CrÃ©er une conversation
  async create(userId?: string): Promise<Conversation>;

  // Ajouter un message (avec transaction)
  async addMessage(conversationId, role, content): Promise<Message>;

  // RÃ©cupÃ©rer l'historique pour Mistral
  async getChatHistory(conversationId): Promise<ChatMessage[]>;
}
```

### 6.3 Transactions Prisma

```typescript
// Garantit l'atomicitÃ© (tout ou rien)
await this.prisma.$transaction([
  this.prisma.message.create({ data: messageData }),
  this.prisma.conversation.update({
    where: { id },
    data: { updatedAt: new Date() },
  }),
]);
```

### 6.4 Niveaux d'isolation

| Niveau          | Description                                         |
| --------------- | --------------------------------------------------- |
| ReadUncommitted | Peut lire des donnÃ©es non validÃ©es                  |
| ReadCommitted   | Ne lit que les donnÃ©es validÃ©es (dÃ©faut PostgreSQL) |
| RepeatableRead  | Lectures cohÃ©rentes dans la transaction             |
| Serializable    | Le plus strict                                      |

---

## 7. Embeddings et Recherche Vectorielle

### 7.1 Qu'est-ce qu'un Embedding ?

Un **embedding** est une reprÃ©sentation vectorielle d'un texte. Il transforme des mots/phrases en tableaux de nombres qui capturent le **sens sÃ©mantique**.

```
"Comment installer Docker ?"
        â†“ generateEmbedding()
[0.023, -0.156, 0.789, 0.034, ...] // 1024 nombres (dimension Mistral)
```

**PropriÃ©tÃ© clÃ©** : Deux textes similaires en sens auront des vecteurs proches dans l'espace.

### 7.2 GÃ©nÃ©ration d'embeddings avec Mistral

```typescript
// src/services/mistral/MistralService.ts

public async generateEmbedding(text: string): Promise<number[]> {
  const response = await this.client.embeddings.create({
    model: 'mistral-embed',
    inputs: [text],
  });
  return response.data[0].embedding; // number[1024]
}

// Version batch (plus efficace pour plusieurs textes)
public async generateEmbeddings(texts: string[]): Promise<number[][]> {
  const response = await this.client.embeddings.create({
    model: 'mistral-embed',
    inputs: texts,
  });
  return response.data.map(item => item.embedding);
}
```

### 7.3 Stockage avec pgvector

**pgvector** est une extension PostgreSQL pour stocker et rechercher des vecteurs.

```sql
-- Activer l'extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Table de documents avec embeddings
CREATE TABLE documents (
  id BIGSERIAL PRIMARY KEY,
  content TEXT,
  embedding vector(1024)  -- Type vector de dimension 1024
);

-- Index pour accÃ©lÃ©rer les recherches (optionnel mais recommandÃ©)
CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

### 7.4 Distance Cosinus

La **distance cosinus** mesure l'angle entre deux vecteurs :

| Distance  | Signification              |
| --------- | -------------------------- |
| 0         | Identiques                 |
| < 0.3     | TrÃ¨s similaires âœ…         |
| 0.3 - 0.6 | LiÃ©s au sujet âš ï¸           |
| > 0.6     | Pas vraiment pertinents âŒ |

```sql
-- OpÃ©rateur <=> pour la distance cosinus dans pgvector
SELECT content, embedding <=> '[0.1, 0.2, ...]'::vector AS distance
FROM documents
ORDER BY distance
LIMIT 5;
```

### 7.5 DocumentService

```typescript
// src/services/document/DocumentService.ts

export class DocumentService {
  // Ajouter un document (embedding gÃ©nÃ©rÃ© automatiquement)
  async addDocument(input: { content: string }): Promise<Document> {
    const embedding = await mistral.generateEmbedding(input.content);
    const embeddingStr = `[${embedding.join(',')}]`;

    // Prisma ne supporte pas nativement pgvector â†’ SQL brut
    return await this.prisma.$queryRawUnsafe(
      `INSERT INTO documents (content, embedding)
       VALUES ($1, $2::vector)
       RETURNING id, content`,
      input.content,
      embeddingStr
    );
  }

  // Recherche sÃ©mantique
  async searchSimilar(query: string, limit = 5): Promise<SearchResult[]> {
    const queryEmbedding = await mistral.generateEmbedding(query);
    const embeddingStr = `[${queryEmbedding.join(',')}]`;

    return await this.prisma.$queryRawUnsafe(
      `SELECT id, content, embedding <=> $1::vector AS distance
       FROM documents
       ORDER BY distance
       LIMIT $2`,
      embeddingStr,
      limit
    );
  }
}
```

### 7.6 Pourquoi $queryRawUnsafe ?

Prisma ne supporte pas nativement le type `vector` de pgvector. On utilise donc :

| MÃ©thode                           | SÃ©curitÃ©     | Usage                                   |
| --------------------------------- | ------------ | --------------------------------------- |
| `prisma.model.create()`           | âœ… SÃ»r       | Types standards (Conversation, Message) |
| `$queryRaw` template              | âœ… SÃ»r       | SQL paramÃ©trÃ© mais limitÃ©               |
| `$queryRawUnsafe` + `$1, $2`      | âœ… SÃ»r       | SQL avec types custom (vector)          |
| `$queryRawUnsafe` + concatÃ©nation | âŒ Dangereux | JAMAIS faire Ã§a !                       |

**Important** : On utilise des paramÃ¨tres positionnels (`$1`, `$2`) qui sont Ã©chappÃ©s par PostgreSQL, donc c'est sÃ©curisÃ©.

### 7.7 Algorithmes de recherche vectorielle

| Algorithme  | Type  | Vitesse        | PrÃ©cision | Usage           |
| ----------- | ----- | -------------- | --------- | --------------- |
| Force brute | Exact | ğŸ¢ Lent        | 100%      | Petits datasets |
| **IVFFlat** | ANN   | ğŸ‡ Rapide      | ~95%      | Bon compromis   |
| **HNSW**    | ANN   | ğŸš€ TrÃ¨s rapide | ~98%      | Production      |

**ANN** = Approximate Nearest Neighbor (sacrifice un peu de prÃ©cision pour la vitesse)

---

## 8. RAG - Retrieval-Augmented Generation

### 8.1 Concept

Le **RAG** permet Ã  un LLM de rÃ©pondre avec des **connaissances externes** (documents privÃ©s, FAQ, etc.) sans fine-tuning.

```
Question utilisateur
        â†“
1. GÃ©nÃ©rer l'embedding de la question
        â†“
2. Chercher les documents similaires en base
        â†“
3. Construire un prompt avec le contexte trouvÃ©
        â†“
4. Envoyer au LLM
        â†“
RÃ©ponse enrichie par les documents
```

### 8.2 Avantages du RAG

| Avantage                         | Description                                |
| -------------------------------- | ------------------------------------------ |
| **DonnÃ©es privÃ©es**              | Le LLM peut rÃ©pondre sur vos docs internes |
| **RÃ©duction des hallucinations** | RÃ©ponses basÃ©es sur des faits              |
| **Pas de fine-tuning**           | Moins coÃ»teux, plus simple                 |
| **Mise Ã  jour facile**           | Ajouter/retirer des docs Ã  chaud           |

### 8.3 ImplÃ©mentation

```typescript
// Exemple de flux RAG complet

async function chatWithRAG(userQuestion: string, conversationId: string) {
  const docs = getDocumentService();
  const mistral = getMistralService();
  const conversations = getConversationService();

  // 1. Chercher les documents pertinents
  const relevantDocs = await docs.searchSimilar(userQuestion, { limit: 3 });

  // 2. Construire le contexte
  const context = relevantDocs.map((doc) => doc.content).join('\n\n---\n\n');

  // 3. CrÃ©er le prompt enrichi
  const systemPrompt = `Tu es un assistant. RÃ©ponds en te basant sur ces documents :

${context}

Si l'information n'est pas dans les documents, dis-le clairement.`;

  // 4. RÃ©cupÃ©rer l'historique et ajouter le system prompt
  const history = await conversations.getChatHistory(conversationId);
  history[0] = { role: 'system', content: systemPrompt };

  // 5. Obtenir la rÃ©ponse
  return await mistral.complete(history);
}
```

### 8.4 Chunking (DÃ©coupage)

Pour les longs documents, on les dÃ©coupe en **chunks** avant de gÃ©nÃ©rer les embeddings :

```typescript
function chunkText(text: string, maxLength = 500): string[] {
  const sentences = text.split(/[.!?]+/);
  const chunks: string[] = [];
  let current = '';

  for (const sentence of sentences) {
    if ((current + sentence).length > maxLength) {
      chunks.push(current.trim());
      current = sentence;
    } else {
      current += sentence + '. ';
    }
  }
  if (current) chunks.push(current.trim());

  return chunks;
}

// Utilisation
const longDocument = '... 5000 mots ...';
const chunks = chunkText(longDocument);
await documentService.addDocuments(chunks); // Chaque chunk a son embedding
```

**Pourquoi ?** Un seul vecteur pour un long document "dilue" le sens. Des chunks permettent une recherche plus prÃ©cise.

### 8.5 StratÃ©gies de chunking

| StratÃ©gie           | Description                | Usage                        |
| ------------------- | -------------------------- | ---------------------------- |
| **Fixed size**      | 500 caractÃ¨res             | Simple, rapide               |
| **Sentence-based**  | Par phrases                | PrÃ©serve le sens             |
| **Paragraph-based** | Par paragraphes            | Documents structurÃ©s         |
| **Overlap**         | Chevauchement entre chunks | Ã‰vite de couper des idÃ©es    |
| **Semantic**        | Par similaritÃ© sÃ©mantique  | Le plus prÃ©cis, mais coÃ»teux |

### 8.6 ModÃ¨les d'embedding

| ModÃ¨le                   | Fournisseur | Dimension | CoÃ»t             |
| ------------------------ | ----------- | --------- | ---------------- |
| `mistral-embed`          | Mistral     | 1024      | ~0.1â‚¬/1M tokens  |
| `text-embedding-3-small` | OpenAI      | 1536      | ~0.02$/1M tokens |
| `text-embedding-3-large` | OpenAI      | 3072      | ~0.13$/1M tokens |
| `all-MiniLM-L6-v2`       | Open source | 384       | Gratuit (local)  |
| `nomic-embed-text`       | Open source | 768       | Gratuit (local)  |

---

## 9. Architecture MVC

### 9.1 Structure des fichiers

```
src/
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ index.ts              # AgrÃ¨ge toutes les routes
â”‚   â”œâ”€â”€ conversationRoutes.ts # Routes /conversations, /chat
â”‚   â””â”€â”€ documentRoutes.ts     # Routes /documents (RAG)
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ conversationController.ts  # Logique HTTP chat
â”‚   â””â”€â”€ documentController.ts      # Logique HTTP documents
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ mistral/
â”‚   â”‚   â”œâ”€â”€ MistralService.ts # Logique IA (chat + embeddings)
â”‚   â”‚   â”œâ”€â”€ types.ts          # Interfaces
â”‚   â”‚   â”œâ”€â”€ errors.ts         # Erreurs custom
â”‚   â”‚   â””â”€â”€ index.ts          # Exports
â”‚   â”œâ”€â”€ conversation/
â”‚   â”‚   â””â”€â”€ ConversationService.ts  # Logique DB conversations
â”‚   â””â”€â”€ document/
â”‚       â””â”€â”€ DocumentService.ts      # Logique DB documents (RAG)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ retry.ts              # Exponential backoff
â”‚   â””â”€â”€ tokenizer.ts          # Sliding window
â””â”€â”€ server.ts                 # Point d'entrÃ©e
```

### 9.2 ResponsabilitÃ©s

| Couche      | ResponsabilitÃ©                            |
| ----------- | ----------------------------------------- |
| Routes      | DÃ©finir les endpoints                     |
| Controllers | GÃ©rer HTTP (req/res), valider, orchestrer |
| Services    | Logique mÃ©tier (IA, DB, Embeddings)       |
| Utils       | Fonctions rÃ©utilisables                   |

### 9.3 Flux d'une requÃªte

```
POST /api/chat
     â”‚
     â–¼
[conversationRoutes.ts]
     â”‚ router.post('/chat', chat)
     â–¼
[conversationController.ts]
     â”‚ - Valide les inputs
     â”‚ - Appelle ConversationService.addMessage()
     â”‚ - Appelle MistralService.streamComplete()
     â”‚ - Renvoie la rÃ©ponse SSE
     â–¼
[MistralService.ts]
     â”‚ - Applique sliding window
     â”‚ - Appelle l'API avec retry
     â”‚ - Yield les chunks
     â–¼
[Mistral API]
```

---

## 10. Frontend Vue.js

### 10.1 Composants

```
frontend/src/
â”œâ”€â”€ views/
â”‚   â””â”€â”€ ChatBot.vue           # Vue principale
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatInput.vue         # Champ de saisie
â”‚   â”œâ”€â”€ ChatMessage.vue       # Bulle de message
â”‚   â””â”€â”€ ChatSidebar.vue       # Liste des conversations
â””â”€â”€ router/
    â””â”€â”€ index.ts              # Vue Router
```

### 10.2 Gestion du streaming

```vue
<script setup>
const messages = ref([]);

async function sendMessage(content) {
  // 1. Ajouter le message user
  messages.value.push({ role: 'user', content });

  // 2. PrÃ©parer le message assistant (vide)
  const assistantIndex = messages.value.length;
  messages.value.push({ role: 'assistant', content: '' });

  // 3. Stream la rÃ©ponse
  const reader = response.body.getReader();
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    // 4. Mettre Ã  jour en temps rÃ©el
    messages.value[assistantIndex].content += chunk;
  }
}
</script>
```

---

## 11. Concepts clÃ©s Ã  retenir

### 11.1 Patterns

| Pattern                  | OÃ¹                   | Pourquoi                               |
| ------------------------ | -------------------- | -------------------------------------- |
| **Singleton**            | MistralService       | Une seule instance, config partagÃ©e    |
| **Dependency Injection** | ConversationService  | TestabilitÃ© (injecter mock Prisma)     |
| **AsyncIterator**        | streamComplete()     | Traiter les donnÃ©es au fur et Ã  mesure |
| **Exponential Backoff**  | withRetry()          | RÃ©silience aux erreurs API             |
| **Sliding Window**       | applySlidingWindow() | GÃ©rer les limites de contexte          |
| **RAG**                  | DocumentService      | Enrichir le LLM avec des docs privÃ©s   |

### 11.2 Bonnes pratiques

1. **SÃ©paration des responsabilitÃ©s** : Routes â†’ Controllers â†’ Services
2. **Typage fort** : Interfaces TypeScript partout
3. **Gestion des erreurs** : Classes d'erreurs custom
4. **Configuration** : Variables d'environnement, pas de hardcode
5. **Logging** : Console.log pour debug, avec prÃ©fixes `[ServiceName]`
6. **ParamÃ¨tres SQL** : Toujours utiliser `$1, $2` au lieu de concatÃ©nation

### 11.3 Points de vigilance

| ProblÃ¨me                 | Solution                       |
| ------------------------ | ------------------------------ |
| Rate limiting (429)      | Retry avec exponential backoff |
| Context overflow (400)   | Sliding window                 |
| Latence UX               | Streaming SSE                  |
| Perte de contexte        | Persistance PostgreSQL         |
| Erreurs silencieuses     | Classes d'erreurs typÃ©es       |
| Longs documents          | Chunking avant embedding       |
| RÃ©sultats non pertinents | Filtrer par maxDistance        |

### 11.4 Commandes utiles

```bash
# GÃ©nÃ©rer le client Prisma
pnpm prisma:generate

# Pousser le schÃ©ma en DB
pnpm db:push

# Reset la DB
pnpm db:push --force-reset

# Logs Docker
docker compose logs app --tail=20
docker compose logs frontend --tail=20

# Activer pgvector
docker compose exec postgres psql -U postgres -d ia_chat -c "CREATE EXTENSION IF NOT EXISTS vector;"

# Voir les documents indexÃ©s
docker compose exec postgres psql -U postgres -d ia_chat -c "SELECT id, LEFT(content, 50) FROM documents;"
```

---

## ğŸ“ Checklist de rÃ©vision

### Architecture & Patterns

- [ ] Je sais expliquer l'architecture MVC
- [ ] Je comprends le pattern Singleton
- [ ] Je sais implÃ©menter un retry avec exponential backoff
- [ ] Je comprends pourquoi le jitter est important
- [ ] Je sais ce qu'est une sliding window et pourquoi c'est nÃ©cessaire

### Streaming & Frontend

- [ ] Je peux expliquer le flux SSE (Server-Sent Events)
- [ ] Je comprends les AsyncIterables (`async *` et `yield`)
- [ ] Je peux consommer un stream cÃ´tÃ© frontend

### Base de donnÃ©es

- [ ] Je sais crÃ©er un schÃ©ma Prisma
- [ ] Je comprends les transactions et niveaux d'isolation
- [ ] Je sais utiliser `$queryRawUnsafe` avec des paramÃ¨tres positionnels

### Embeddings & RAG

- [ ] Je comprends ce qu'est un embedding (texte â†’ vecteur)
- [ ] Je sais gÃ©nÃ©rer un embedding avec `mistral-embed`
- [ ] Je comprends la distance cosinus et comment l'interprÃ©ter
- [ ] Je sais stocker des vecteurs avec pgvector
- [ ] Je peux implÃ©menter une recherche sÃ©mantique
- [ ] Je comprends le concept de RAG et son utilitÃ©
- [ ] Je sais pourquoi le chunking est important pour les longs documents

---

_Document mis Ã  jour le 17/12/2024_
